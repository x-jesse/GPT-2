# OpenAI GPT-2 Re-Implementation

This is a re-implementation of the GPT-2 (124M) model in PyTorch based on the OpenAI paper [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) and Andrej Karpathy's Youtube series [Neural Networks: Zero to Hero](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ).

## Table of Contents


